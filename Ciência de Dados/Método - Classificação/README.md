# Modelo de ClassificaÃ§Ã£o: PrediÃ§Ã£o de Renda Anual (>50K)

Este trabalho utiliza o dataset do Kaggle â€“ Salary Prediction Classification[https://www.kaggle.com/datasets/ayessa/salary-prediction-classification/data], com informaÃ§Ãµes socioeconÃ´micas e demogrÃ¡ficas de indivÃ­duos, para prever se uma pessoa pertence Ã  faixa de renda >50K.

O modelo desenvolvido, em um cenÃ¡rio real de um banco, permite identificar clientes com alta renda e direcionar produtos exclusivos apenas para quem tem perfil >50K, aumentando a eficiÃªncia e reduzindo custos. AlÃ©m disso, ajuda na gestÃ£o de risco de crÃ©dito, prevenindo inadimplÃªncia e permitindo aprovaÃ§Ãµes automÃ¡ticas de limites com base na renda prevista. Por fim, possibilita personalizar a experiÃªncia do cliente, oferecendo produtos no momento certo e evitando que clientes valiosos migrem para a concorrÃªncia, fortalecendo retenÃ§Ã£o e oportunidades de cross-selling.

## ğŸ¯ Objetivos do Projeto

* **ClassificaÃ§Ã£o**: Diferenciar indivÃ­duos com renda `<=50K` de indivÃ­duos com renda `>50K`.
* **Pipeline de Dados**: Implementar transformaÃ§Ãµes automatizadas, como padronizaÃ§Ã£o de escalas e codificaÃ§Ã£o de variÃ¡veis categÃ³ricas.
* **OtimizaÃ§Ã£o de Modelos**: Comparar diferentes algoritmos utilizando validaÃ§Ã£o cruzada para garantir a estabilidade das mÃ©tricas de desempenho.

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

O fluxo de trabalho foi estruturado utilizando a biblioteca `scikit-learn` em Python:

1.  **Tratamento de Dados**:
    * Limpeza de valores ausentes e tratamento de variÃ¡veis categÃ³ricas.
    * PadronizaÃ§Ã£o de variÃ¡veis numÃ©ricas, como idade e ganho de capital.
2.  **Modelos Avaliados**: ComparaÃ§Ã£o via validaÃ§Ã£o cruzada (K-Fold Estratificado) de quatro algoritmos:
    * **Logistic Regression**: Atuou como modelo base (*baseline*); embora estÃ¡vel, sua natureza linear limitou a captura de relaÃ§Ãµes complexas (Acc: 83.99%).
    * **SVC (Support Vector Classifier)**: Buscou o hiperplano de separaÃ§Ã£o mÃ¡xima, beneficiando-se da padronizaÃ§Ã£o de escalas (Acc: 85.17%).
    * **Random Forest**: MÃ©todo de *Ensemble* (Bagging) que reduziu o sobreajuste ao combinar mÃºltiplas Ã¡rvores independentes (Acc: 86.02%).
    * **Gradient Boosting (GBC)**: O **modelo vencedor**; constrÃ³i Ã¡rvores sequencialmente para corrigir erros residuais, capturando interaÃ§Ãµes sutis entre os dados (Acc: 86.37%).
3.  **MÃ©tricas de AvaliaÃ§Ã£o**:
    * **AcurÃ¡cia e F1-Score**: Para medir a precisÃ£o e o equilÃ­brio entre sensibilidade e especificidade.
    * **Matriz de ConfusÃ£o e Curva ROC**: DiagnÃ³stico detalhado das prediÃ§Ãµes.



## ğŸ“ˆ Principais Resultados

O modelo de **Gradient Boosting** superou os demais em termos de acurÃ¡cia e equilÃ­brio de classificaÃ§Ã£o (F1-Score).

### Desempenho dos Modelos (ValidaÃ§Ã£o Cruzada)
| Modelo | Acc MÃ©dia | F1 MÃ©dia | Std |
| :--- | :---: | :---: | :---: |
| **GradientBoostingClassifier** | **86.37%** | **85.75%** | **0.005** |
| RandomForestClassifier | 86.02% | 85.28% | 0.003 |
| SVC | 85.17% | 84.50% | 0.004 |
| LogisticRegression | 83.99% | 83.44% | 0.002 |

### ğŸ§ª Performance no Conjunto de Teste (Dados NÃ£o Observados)

Os resultados mostram que o modelo foi bem ajustado. A acurÃ¡cia no treino (86,99%) e no teste (86,28%) sÃ£o prÃ³ximas, o que indica que nÃ£o houve overfitting â€” ou seja, o modelo nÃ£o decorou os dados, ele aprendeu padrÃµes que generalizam bem para novos dados.

O modelo tem desempenho diferente entre as classes:

* Para a classe â‰¤50K, ele apresenta precisÃ£o de 88% e recall de 95%, resultando em um F1-score de 0,91. Isso acontece porque essa Ã© a classe majoritÃ¡ria (4531 casos), entÃ£o o modelo tem mais exemplos para aprender.
* Para a classe >50K (1502 casos), a precisÃ£o Ã© 79%, o que significa que, quando o modelo prevÃª alta renda, ele geralmente estÃ¡ correto. PorÃ©m, o recall Ã© 61%, indicando que ele deixa passar parte das pessoas que realmente ganham mais de 50K.

* **Curva ROC**: O modelo apresentou um valor de **AUC de aproximadamente 0.92**, confirmando uma excelente capacidade discriminatÃ³ria entre as classes de renda.
  
### Perfil de Alta Renda (Feature Importance)
O modelo identificou que os fatores com maior impacto na probabilidade de renda >50K sÃ£o:
1.  **Estado Civil**: Forte correlaÃ§Ã£o positiva para indivÃ­duos casados.
2.  **EducaÃ§Ã£o**: NÃ­veis de escolaridade mais altos elevam significativamente a chance de alta renda.
3.  **Idade e Carga HorÃ¡ria**: A experiÃªncia profissional e o tempo dedicado ao trabalho semanal sÃ£o determinantes.
4.  **Investimentos**: Ganhos de capital recorrentes sÃ£o preditores fundamentais.

## ğŸ› ï¸ Tecnologias Utilizadas

* **Linguagem**: Python.
* **Bibliotecas**: `pandas`, `scikit-learn`, `matplotlib`, `seaborn`.
* **Ambiente**: Jupyter Notebook / Google Colab.

## ğŸ“ Estrutura do RepositÃ³rio

* `Modelo de classificaÃ§Ã£o - Machine Learning.ipynb`: Notebook com o cÃ³digo e anÃ¡lise exploratÃ³ria.
* `Modelo de classificaÃ§Ã£o - Machine Learning.html`: RelatÃ³rio final compilado com as visualizaÃ§Ãµes e mÃ©tricas.
* `salary.csv`: Banco de dados utilizado para o trabalho.

---
*Projeto desenvolvido para o estudo de algoritmos de aprendizado supervisionado e interpretaÃ§Ã£o de modelos de Ensemble.*
